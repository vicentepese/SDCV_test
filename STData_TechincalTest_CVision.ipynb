{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29a8ae93-4689-426f-82d8-162b710ce905",
   "metadata": {},
   "source": [
    "# Seedtag Datascience - Computer Vision Technical Test\n",
    "\n",
    "In this technical test, you are asked to solve different Computer Vision tasks using the SVHN dataset:\n",
    "\n",
    "1. For each task, we provide all the instructions and some sample code to perform basic operations and/or to clarify the problem. The provided code is implemented using libraries such as NumPy, PyTorch and PyTorchLightning. However, you are completely free to use any other library that you consider to solve the problems.\n",
    "\n",
    "2. The solution for each exercise should be implemented in a JupyterNotebook similar as this one. You will need to submit a file called 'STData_CVision_Solution_YOURNAME.ipynb\" when your test is finished. Additionally, you can also attach a zip file with other data (figures,images, reports) that you have generated if you consider them relevant ( conveniently reference and discussed in the notebook) .\n",
    "\n",
    "3. It is very important that, apart from solving the task, you also motivate the different decisions that you take when solving them and discuss properly the different results that you obtain.\n",
    "\n",
    "Good luck!!!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58d2c4f-79a4-4b97-ad12-3eb34d49a6a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 0. Package installation and SVHN Dataset downloading\n",
    "\n",
    "Installation of basic packages to run the provided examples. If you use any other libraries, you can modify the following list accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5972cba5-0f3a-4436-a73a-69b45a61e8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scipy\n",
    "%pip install torch\n",
    "%pip install torchvision\n",
    "%pip install scipy\n",
    "%pip install numpy\n",
    "%pip install pytorch_lightning\n",
    "%pip install torchmetrics\n",
    "%pip install matplotlib\n",
    "%pip install IProgress\n",
    "%pip install ipywidgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc64596-2f72-44df-81a8-0350f7eb88af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "torchvision.datasets.SVHN('./data','train',download=True)\n",
    "torchvision.datasets.SVHN('./data','test',download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d824d0c6-2fab-4b58-b1fc-27f50e91be82",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. SVHN Dataset\n",
    "\n",
    "1. The SVHN dataset contains 32x32 pixels color images depicting digits from 0 to 9.\n",
    "2. The original training and testing splits contain ~73K and ~26K images, respectively. The digit labels for each split and image are also provided\n",
    "3. Two files containing the images and labels from both splits are saved in the \"./data\" folder as numpy arrays.\n",
    "\n",
    "For each task in the test, you will need to use different splits of the dataset. In the following, we provide the code to load the different splits and an example of how to visualize images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bc66ac-50db-46c4-973f-e06ee7f38922",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.1 Loading a specific split for a given task\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f5f025-bc2c-4edd-9aac-51fb21b41947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def load_data(root_dir, split):\n",
    "    \n",
    "    filename = os.path.join(root_dir,'test_32x32.mat')\n",
    "    if(split.startswith('train') or split.startswith('unlabelled')):\n",
    "        filename = os.path.join(root_dir,'train_32x32.mat') \n",
    "    elif(split.startswith('test')):\n",
    "        filename = os.path.join(root_dir,'test_32x32.mat')\n",
    "    \n",
    "    loaded_mat = sio.loadmat(filename)\n",
    "    imgs = (loaded_mat['X']/255).astype(np.float32)\n",
    "    labels = loaded_mat['y'].astype(np.int64).squeeze()\n",
    "    if(split=='train_29_task2'):\n",
    "        imgs_idx_01 =  np.logical_or(labels==10,labels==1)\n",
    "        imgs_idx_29 = np.where(np.logical_not(imgs_idx_01))\n",
    "        imgs = imgs[:,:,:,imgs_idx_29]\n",
    "        labels = labels[imgs_idx_29]\n",
    "    elif(split=='test_01_task2' or split=='train_01_task2'):\n",
    "        imgs_idx_01 =  np.where(np.logical_or(labels==10,labels==1))[0]\n",
    "        if(split=='train_01_task2'):\n",
    "            imgs_idx_01 = imgs_idx_01[0:200]\n",
    "        else:\n",
    "            imgs_idx_01 = imgs_idx_01[200::]\n",
    "        imgs = imgs[:,:,:,imgs_idx_01]\n",
    "        labels = labels[imgs_idx_01]\n",
    "    if(split=='test_task3'):\n",
    "        N = 50\n",
    "        imgs = imgs[:,:,:,0:N]\n",
    "        labels = labels[0:N]\n",
    "    print('Loaded SVHN split: {split}'.format(split=split))\n",
    "    print('-------------------------------------')\n",
    "    print('Images Size: ' , imgs.shape[0:-1])\n",
    "    print('Split Number of Images:', imgs.shape[-1])\n",
    "    print('Split Labels Array Size:', labels.shape)\n",
    "    print('Possible Labels: ', np.unique(labels))\n",
    "    return imgs,labels\n",
    "#\n",
    "split_images, split_labels = load_data('./data','train_29_task2')\n",
    "split_images, split_labels = load_data('./data','test_01_task2')\n",
    "split_images, split_labels = load_data('./data','train_01_task2')\n",
    "#\n",
    "split_images, split_labels = load_data('./data','train_task1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1771b105-0aea-4f59-b6ec-4ffdd93d88e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.2 VIsualizing images and their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9162b778-3db1-4ca3-99e6-bd5059b9e4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Visualize images and its labels\n",
    "def visualize_image(images, labels, index):\n",
    "    img = images[:,:,:,index]\n",
    "    label = labels[index]\n",
    "    plt.imshow((img))\n",
    "    plt.text(1, 3, 'Label: {label}'.format(label=label), c = 'red', fontsize= 20,\n",
    "             bbox=dict(fill=False, edgecolor='red', linewidth=2))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "image_index = 10\n",
    "visualize_image(split_images,\n",
    "                split_labels,\n",
    "                image_index)\n",
    "\n",
    "image_index = 50\n",
    "visualize_image(split_images,\n",
    "                split_labels,\n",
    "                image_index)\n",
    "\n",
    "image_index = 2000\n",
    "visualize_image(split_images,\n",
    "                split_labels,\n",
    "                image_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6483f365-3a2e-484e-9099-15d46bc8751f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Task 1 (T1) - Image Classification\n",
    "\n",
    "In this task, the goal is to create  a classification model to identify the digit labels for each image. For this purpose, you are provided with:\n",
    "1. A training set corresponding to the original train split of the SVHN dataset (previously introduced)\n",
    "2. A testing set corresponding to the original test split. \n",
    "\n",
    "With the provided data, you need to develop a model classifying images into the different digit classes. Your goal is to obtain the maximum possible accuracy in the testing set with the following instructions:\n",
    "1. You can use any existing implemented method and any external library that you consider.\n",
    "2. The testing set can only be used for evaluation puproses.\n",
    "3. In case that you train a parametric model (e.g, a neural network), it can not contain more than 200K parameters.\n",
    "3. Apart from accuracy, you can also report and discuss any other evaluation metric that you consider relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4b5fdb-1349-4524-a489-55ec164e76bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## T1.1 - Pytorch Example\n",
    "\n",
    "In the following, we provide a simple solution to the task by training a Multi-Layer perceptron with a single hidden layer using:\n",
    "1. A cross entropy loss during learning.\n",
    "2. A hidden layer with 64 neurons and a Rectified Linear Unit activation function.\n",
    "2. Stochastic Gradient Descent for optimization with learning rate of 5e-2 and a batch size of 64 samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4457253-ef3a-433f-a573-eaaf558f4a34",
   "metadata": {
    "tags": []
   },
   "source": [
    "### T1.1.1 - SVHN Dataset class\n",
    "\n",
    "Implementation example of a PyTorch dataset class to load the different SVHN splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fce79d8-65d6-4514-93b4-6115fb490d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as F\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class SVHNDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 root_dir, \n",
    "                 split, \n",
    "                 transform=None):\n",
    "        self.images, self.labels = load_data(root_dir, split)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.images[:,:,:,index], int(self.labels[index])\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, target-1\n",
    "\n",
    "train_dataset = SVHNDataset('./data','train_task1',\n",
    "                            transform = transforms.ToTensor())\n",
    "img_index = 40 \n",
    "visualize_image(train_dataset.images, \n",
    "                train_dataset.labels, \n",
    "                img_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dff751f-7295-4ecb-8637-a4910440fcc7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### T1.1.2 - Model definition with Pytorch Lightning\n",
    "Implementation example using Pytorch Lightning of a Neural Network composed of single fully-connected hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d02053-37b7-4890-ba71-432d729a4c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch.nn as nn\n",
    "from  torch.utils.data import DataLoader\n",
    "import torchmetrics\n",
    "class MLP(pl.LightningModule):\n",
    "    def __init__(self, \n",
    "                 in_features, \n",
    "                 hidden_features, \n",
    "                 n_classes):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(in_features, hidden_features)\n",
    "        self.layer2 = nn.Linear(hidden_features, n_classes)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        self.train_accuracy = torchmetrics.Accuracy()\n",
    "        self.val_accuracy = torchmetrics.Accuracy()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.activation(self.layer1(x))\n",
    "        out = self.layer2(h)\n",
    "        return out\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=5e-2)\n",
    "        return optimizer\n",
    "    \n",
    "    def compute_step(self,batch):\n",
    "        imgs, labels = batch\n",
    "        imgs = imgs.view(imgs.size(0), -1)\n",
    "        label_logits = self.forward(imgs)\n",
    "        _,label_predictions = torch.max(label_logits, dim=1 )\n",
    "        return self.loss(label_logits,labels), labels, label_predictions\n",
    "    \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        loss, labels, label_predictions = self.compute_step(train_batch)\n",
    "        self.train_accuracy(label_predictions, labels)\n",
    "        self.log_dict({\"train/loss\": loss, 'train/acc' : self.train_accuracy}, \n",
    "                  on_step=False, \n",
    "                  on_epoch=True, \n",
    "                  prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        loss, labels, label_predictions = self.compute_step(val_batch)\n",
    "        self.val_accuracy(label_predictions, labels)\n",
    "        self.log_dict({\"val/loss\": loss, 'val/acc' : self.val_accuracy}, \n",
    "                  on_step=False, \n",
    "                  on_epoch=True, \n",
    "                  prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a816ad-0031-4c91-9e68-606b616b6251",
   "metadata": {
    "tags": []
   },
   "source": [
    "### T1.1.3 Model training/evaluation and visualizantion with tensorboard \n",
    "Example of training the defined model with Pytorch Lightning, logging training and evaluation metrics and visualizing them with Tensorboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222e874a-7216-4af1-b530-6970fb5c044c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import loggers as pl_loggers\n",
    "\n",
    "train_data_ex1 = SVHNDataset('./data','train_task1',\n",
    "                             transform = transforms.ToTensor())\n",
    "test_data_ex1 = SVHNDataset('./data','test_task1',\n",
    "                            transform = transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(train_data_ex1, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data_ex1, batch_size=64, shuffle=False)\n",
    "\n",
    "in_features = 32*32*3\n",
    "hidden_features = 64\n",
    "n_classes = 10 \n",
    "model = MLP(in_features,\n",
    "            hidden_features,\n",
    "            n_classes)\n",
    "\n",
    "tb_logger = pl_loggers.TensorBoardLogger(\"./logs/\")\n",
    "trainer = pl.Trainer(gpus=1,max_epochs=10,logger = tb_logger)\n",
    "trainer.fit(model, \n",
    "           train_loader, \n",
    "           test_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13efa30f-e5d7-41ac-a5cc-dd59ddbe51e5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### T1.2 - Training and testing results visualized on tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6221b1-b53a-409a-a170-ed190bfd25e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39aaf6c8-6f22-405e-a37e-198f95303d57",
   "metadata": {},
   "source": [
    "As can be observed, the model contains 196K parameters which is under the contraints given by the exercise.\n",
    "Additionally, the model achieves around a 60% accuracy on the validation set as can be visualized in the Tensorboad Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e14a2c-7f3d-4ff6-8074-bc23f19c3c64",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Task 2 - Image Classification with scarce training data\n",
    "In this task, the goal is to create a model which is able to perform binary classification and differentiate between images depicting the digit 0 or 1. For this purpose, you are provided with:\n",
    "1. A training set containing images with digits from 2 to 9. This dataset is large and is composed by a total of XXX examples. \n",
    "2. A training set containing images with digits from 0 to 1. This split is small and only contains XXX examples.\n",
    "3. A testing set with image digits from 0 to 1. This dataset is larger than the previous one and must be used for evaluation purposes. \n",
    "\n",
    "With the provided data, train the model classifying 0 and 1s and evaluate its performance in terms of accuracy. Your goal is to obtain the maximum possible accuracy in the testing set by following the model constratints described in Task 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dd37cf-8c07-4d1b-8d2b-ac616695e95a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### T2.1 - Loading datasets from the different splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb14044d-82a6-4f9e-906f-2e66b44e3b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import SVHN\n",
    "\n",
    "train_29_imgs, train_29_labels = load_data('./data','train_29_task2')\n",
    "train_01_imgs, train_01_labels = load_data('./data','train_01_task2')\n",
    "test_01_imgs, test_01_labels = load_data('./data','test_01_task2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4495e502-2322-4098-8665-3bd20d10a50b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Task 3 - Image Classification with unlabelled training data\n",
    "In this task, you are provided with the following data splits:\n",
    "\n",
    "1. An unlabelled set containing images with digits from 0 to 9. This dataset corresponds to the original SVHN training set.  \n",
    "2. A small subset of 50 unlabelled images with digits also ranging from 0 to 9.\n",
    "\n",
    "Given any query image $\\mathbf{x}$ in the small unlabelled dataset, your goal is to estimate what are the 5 most similar images in the large unlabelled dataset. Intuitively, you are interested in retrieving images which contain the same digit than the query image. For instance, if the query image contains the digit 0, you would like that the 5 retrieved images depict the number 0. \n",
    "\n",
    "The goal is to maximize a metric measuring the percentage of retrieved images that correspond to the same digit label than the query image. \n",
    "However, it is important to  remember that both splits are assumed to not be annotated and that you can only use the provided labels for evaluation purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d16a5dd-a4e6-4d1e-8c9b-cadc482a8d07",
   "metadata": {
    "tags": []
   },
   "source": [
    "### T3.1 - Solution example comparing images using euclidean distance\n",
    "In the following, we provide a simple solution to this problem by:\n",
    "1. Computing the distance in terms of L2 distance between the  query image and all the images in the large unlabelled dataset.\n",
    "2. Retrieving the top 5 images with the minimum distance.\n",
    "\n",
    "We also provide an example of how to visualize results and compute the target metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7279f42f-8c4d-4385-a679-930bf1da7252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "\n",
    "# Load both splits\n",
    "unlabelled_imgs, unlabelled_labels = load_data('./data','unlabelled_task3')\n",
    "test_imgs, test_labels = load_data('./data','test_task3')\n",
    "\n",
    "# Vectorize all the images in both splits\n",
    "unlabelled_imgs_T = unlabelled_imgs.reshape(-1,unlabelled_imgs.shape[-1]).T\n",
    "test_imgs_T = test_imgs.reshape(-1,test_imgs.shape[-1]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2769163e-2b87-46bd-a253-d94cd0796e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the TOP5 retrieved images for a given quary using euclidean distance-based similarity\n",
    "K = 5\n",
    "\n",
    "# Load a given query image form the test set\n",
    "img_idx = 30\n",
    "img = test_imgs_T[img_idx,:]\n",
    "\n",
    "\n",
    "# Compute euclidean metric\n",
    "distances = ((unlabelled_imgs_T-img)**2).sum(axis=1)\n",
    "\n",
    "# Get top10 most similar images\n",
    "similar_img_idx = (distances).argsort()[:K]\n",
    "\n",
    "# Visualize images\n",
    "print('Query Image')\n",
    "visualize_image(test_imgs, test_labels,\n",
    "                img_idx)\n",
    "print('Retrieved Similar Images')\n",
    "for idx in similar_img_idx:\n",
    "    visualize_image(unlabelled_imgs, unlabelled_labels,\n",
    "                    idx)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810ee630-ac46-4b0d-be9d-ebe11e46722f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_accuracies = [] \n",
    "K = 5\n",
    "N = test_imgs.shape[0]\n",
    "for img_idx in range(0,N):\n",
    "    img = test_imgs_T[img_idx,:]\n",
    "    distances = ((unlabelled_imgs_T-img)**2).sum(axis=1)\n",
    "    idx = (distances).argsort()[:K]\n",
    "    similar_img_labels = unlabelled_labels[idx]\n",
    "    img_label = test_labels[img_idx]\n",
    "    image_accuracy = (similar_img_labels==img_label).mean()\n",
    "    img_accuracies.append(image_accuracy)\n",
    "    print('Accuracy for test sample {idx} with label {label}  in TOP{K} retrieved images: {acc}'.format(idx=img_idx,\n",
    "                                                                                                        label= img_label,\n",
    "                                                                                                        K=K,\n",
    "                                                                                                        acc = image_accuracy))\n",
    "\n",
    "# Compute average accuracy over testing set    \n",
    "average_acc = np.asarray(img_accuracies).mean()\n",
    "print('Average Accuracy over the testing set: {acc}'.format(acc=average_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stml-learn",
   "language": "python",
   "name": "stml-learn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
